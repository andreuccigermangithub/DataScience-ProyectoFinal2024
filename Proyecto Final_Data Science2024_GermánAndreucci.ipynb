{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se importan todas las librerías necesarias para trabajar en el proyecto\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error,  make_scorer, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadGitHubUrl(url):\n",
    "  try:\n",
    "    dataframe = pd.read_csv(url)\n",
    "    return dataframe\n",
    "  except Exception as e:\n",
    "    print(f\"Error al leer el archivo CSV desde la URL. Detalles: {e}\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura del dataset desde el repositorio de Github\n",
    "df1 = ReadGitHubUrl('https://raw.githubusercontent.com/andreuccigermangithub/DataScience-ProyectoFinal2024/main/healthcare-stroke-data.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuación información estadística del dataset\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuación información de los tipos de datos de cada columna\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico que muestra los datos faltantes en el dataset con missingno\n",
    "%matplotlib inline\n",
    "msno.matrix(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden observar datos faltantes en la columna de BMI (índice de masa corporal), por lo cual se procede a tratar y corregir éste inconveniente en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuación se comprueba la normalidad de los valores proporcionados en la columna \"BMI\" \n",
    "# para decidir que método es más conveniente a la hora de reemplezar los valores NAN que contiene.\n",
    "stat, pvalue = shapiro(df1[\"bmi\"].dropna())\n",
    "\n",
    "if pvalue > 0.05:\n",
    "    print(\"La distribución de los datos es normal.\")\n",
    "else:\n",
    "    print(\"La distribución de los datos no es normal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al no poseer distribución normal, se opta por reemplezar los datos NAN con la mediana de la columna\n",
    "mediana = df1[\"bmi\"].median()\n",
    "df1[\"bmi\"].fillna(mediana, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para comprobar que los datos fueron reemplezados satisfactoriamente, se grafica nuevamente con missingno\n",
    "%matplotlib inline\n",
    "msno.matrix(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# También a través del siguiente comando confirmo la coincidencia en la cantidad de valores no nulos de todas las columnas\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots para la verificación de outliers de las columna de \"Edad\", \"Nivel promedio de glucosa\", e \"Índice de masa corporal\".\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14, 2))\n",
    "\n",
    "sns.boxplot(x=df1[\"age\"], palette=\"Reds\", ax=axs[0])\n",
    "sns.boxplot(x=df1[\"avg_glucose_level\"], palette=\"Blues\", ax=axs[1])\n",
    "sns.boxplot(x=df1[\"bmi\"], palette=\"Greens\", ax=axs[2])\n",
    "\n",
    "axs[0].set_title(\"Edad de los pacientes\")\n",
    "axs[1].set_title(\"Nivel de glucosa promedio\")\n",
    "axs[2].set_title(\"Índice de masa corporal (BMI)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A través de los boxplots, se analizan los valores outliers del dataset, que en éste caso corresponden a Edad de pacientes, Nivel de glucosa promedio e Índice de masa corporal. Para éstos últimos dos mencionados, se confirma la existencia de valores *anormales* dentro del dataset.\n",
    "En el caso del nivel promedio de glucosa, aparecen valores solamente por encima del valor máximo dentro del boxplot. Y para el caso del BMI, se nota un solo valor por debajo del mínimo, una cantidad considerable inmediatamente luego del valor máximo, y además unos pocos que casi duplican el valor máximo del boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para corroborar la validez de la información obtenida en el dataset, se procede a verificar si existen valores duplicados dentro del\n",
    "# dataset que puedan estar alterando los resultados a la hora de manipularlos. Se elige la columna \"id\" para comprobar si se repite la\n",
    "# información de algún paciente por error.\n",
    "\n",
    "# Verificación de valores duplicados en la columna \"id\" del dataset.\n",
    "dup_id = df1[\"id\"].duplicated()\n",
    "\n",
    "# Conteo de la cantidad de True en la columna \"dup_id\"\n",
    "cant_dup = dup_id.sum()\n",
    "\n",
    "# Mensaje\n",
    "if cant_dup == 0:\n",
    "    print(\"No existen datos duplicados en el dataset\")\n",
    "else:\n",
    "    print(f\"Existen {cant_dup} cantidad de datos duplicados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Abstract**\n",
    "El siguiente trabajo presenta la información médica de un grupo de pacientes, de los cuales una determinada cantidad ha sufrido paro cardíaco al menos una vez. Los datos obtenidos corresponden tanto a su vida personal como así también a su salud en los distintos aspectos. Algunos de estos son estado civil, tipo de empleo, nivel de glucosa, tabaquismo, etc. Con el análisis de los datos proporcionados se pretende determinar que factores combinados contribuyen a que las personas sean más propensas a sufrir un paro cardíaco . De esta forma, se puede ayudar a los médicos a tomar medidas para reducir el riesgo de estos eventos, como recomendar cambios en el estilo de vida o prescribir medicamentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contexto**\n",
    "\n",
    "La prepaga de salud *HealthArg* pretende realizar un estudio analítico sobre sus clientes/pacientes que le permita determinar cuales son los valores y variables que aumentan las probabilidades de sufrir un paro cardíaco entre su nómina. De esta forma, con un modelo de predicción adecuado y eficaz, podrán en primer lugar que pacientes corren un mayor peligro de sufrir el paro. Por otro lado, este tipo de predicción contribuiría a reorganizar también su modelo de negocio, analizando que pacientes, pueden en un futuro presentar un mayor gasto en la cobertura de su servicio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelo predictivo**\n",
    "\n",
    "Para llevar a cabo este modelo predictivo, se cree que se debe utilizar un modelo supervisado. La razón principal es que se dispone de información sobre si el paciente sufrió un paro cardíaco o no. Esta información se puede utilizar para entrenar el modelo y que aprenda a identificar los patrones que asocian los factores de riesgo con el paro cardíaco.\n",
    "\n",
    "Se puede utilizar un modelo de regresión lineal para predecir las probabilidades de un paciente de sufrir un paro cardíaco. La regresión lineal se puede utilizar para este tipo de tareas porque asume que la relación entre la variable independiente y la variable dependiente es lineal. Esto significa que la probabilidad de que un paciente sufra un paro cardíaco puede expresarse como una función lineal de los factores de riesgo.\n",
    "\n",
    "Por ejemplo, se ha demostrado que la edad y el sexo masculino son factores de riesgo independientes para el paro cardíaco. Esto significa que la probabilidad de paro cardíaco aumenta con la edad y es mayor en los hombres que en las mujeres. Estas relaciones pueden modelarse mediante una función lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hipótesis planteada**\n",
    "A continuación se plantean las hipótesis  y respectivos gráficos para llevar a cabo el estudio del dataset incorporado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hipótesis 1:\n",
    "Un mayor nivel de glucosa en los adultos mayores de 50 años incrementa las probabilidades de padecer un ataque cardíaco.\n",
    "Para avanzar con ésta afirmación se propone un gráfico tipo scatterplot que muestra la relación existente entre el nivel promedio de glucosa de los pacientes y su edad. Se puede observar que éste nivel se mantiene distribuida de forma homogénea entre 50 y aproximadamnte 110 para todas las edad. Pero la situación cambia al incrementarse la edad ya que para aquellos entre aproximadamente 50 años y 80 hay una gran concentración en los niveles altos de glucosa, desde 175 hasta 250.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gráfico scatterplot de relación edad/nivel de glucosa\n",
    "\n",
    "# Obtención de datos\n",
    "edad = df1['age']\n",
    "nivel_glucosa_prom = df1['avg_glucose_level']\n",
    "\n",
    "# Creación del gráfico\n",
    "plt.scatter(edad, nivel_glucosa_prom)\n",
    "\n",
    "# Títulos y las etiquetas\n",
    "plt.title('Relación entre la edad y el nivel de glucosa')\n",
    "plt.xlabel('Edad')\n",
    "plt.ylabel('Nivel de glucosa promedio')\n",
    "\n",
    "# Gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figtext\n",
    "hombres = df1.loc[df1[\"gender\"] == \"Male\"]\n",
    "mujeres = df1.loc[df1[\"gender\"] == \"Female\"]\n",
    "\n",
    "#Crea la figura y los subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Gráfico para mujeres\n",
    "sns.scatterplot(x=mujeres[\"age\"], y=mujeres[\"avg_glucose_level\"], color=\"violet\", ax=ax1, label=\"Mujeres\")\n",
    "ax1.set_xlabel(\"Edad\")\n",
    "ax1.set_ylabel(\"Nivel Promedio de Glucosa\")\n",
    "\n",
    "# Gráfico para hombres\n",
    "sns.scatterplot(x=hombres[\"age\"], y=hombres[\"avg_glucose_level\"], color=\"green\", ax=ax2, label=\"Hombres\")\n",
    "ax2.set_xlabel(\"Edad\")\n",
    "ax2.set_ylabel(\"Nivel Promedio de Glucosa\")\n",
    "\n",
    "# Ajusta el espacio entre subplots\n",
    "plt.subplots_adjust(wspace=0.35)\n",
    "\n",
    "figtext(0.49, 0.95, 'Relación entre la edad y el nivel de glucosa según género', ha='center', va='top', fontsize=14)\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hipótesis 2:\n",
    "Aquellos pacientes que han declarado ser fumadores son mas propensos a sufrir un ataque cardíaco que aquellos que dicen haber dejado éste hábito.\n",
    "En este caso, utilizando un gráfico de barra primero se evalúa a los pacientes respecto a su estado y relación con el tabaquismo. Una gran mayoría jamás ha fumado, mientras que aproximadamente la mitad de ellos fumaba hasta el momento del estudio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gráfico para los distintos estados de tabaquismo\n",
    "\n",
    "# Conteo del número de casos para cada categoría\n",
    "counts = df1[\"smoking_status\"].value_counts()\n",
    "\n",
    "# Creación del barplot\n",
    "sns.barplot(x=counts.index, y=counts.values, palette='viridis')\n",
    "\n",
    "# Adición de títulos y etiquetas\n",
    "plt.title(\"Distribución del estado del tabaquismo\")\n",
    "plt.ylabel('Cantidad de pacientes')\n",
    "plt.xlabel('Estado del tabaquismo')\n",
    "\n",
    "# Gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hipótesis 3:\n",
    "La edad es un factor fundamental que determina la probabilidad de sufrir un ataque, siendo que a mayor edad de la persona, mayores son las chances. Esto se debe al desmejoramiento de salud de los pacientes al incrementar su edad.\n",
    "Para analizar la distribución de las edades de aquellos pacientes que han sufrido un ataque cardíaco, se opta por mostrar ésta información con un histograma. Se puede ver que a partir de los 50 años hay un aumento notable respecto a las edades inferiores, el cual siguen aumentando de manera paulatina. Pero realmente hay un incremento muy notorio a partir de los 73/74 años donde ya hay mas de 100 casos, duplicando con creces el rango anterior. Ésto deja en evidencia que a partir de estas edades, las probabilidades de sufrir un ataque cardíaco son mucho mas altas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gráfico tipo histograma para distribución de edades de pacientes que han sufrido para cardíaco\n",
    "\n",
    "# Creación de un DataFrame de personas que han sufrido para cardíaco\n",
    "stroke_df = df1[df1[\"stroke\"] == 1]\n",
    "\n",
    "# Creación de una Series con las edades de las personas que han sufrido ataque cardíaco\n",
    "stroke_ages = stroke_df[\"age\"]\n",
    "\n",
    "# Creación del histograma\n",
    "sns.histplot(stroke_ages, bins=10)\n",
    "\n",
    "# Adición de títulos y etiquetas\n",
    "plt.title(\"Distribución de las edades de personas que han sufrido un ataque\")\n",
    "plt.xlabel(\"Edad\")\n",
    "plt.ylabel(\"Cantidad de afectados\")\n",
    "\n",
    "# Gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico tipo histograma para distribución de edades de pacientes que han sufrido para cardíaco\n",
    "\n",
    "# Creación de un DataFrame de personas que han sufrido para cardíaco\n",
    "stroke_df = df1[df1[\"stroke\"] == 1]\n",
    "\n",
    "hombres = stroke_df.loc[stroke_df[\"gender\"] == \"Male\"]\n",
    "hombres_edades = hombres[\"age\"]\n",
    "\n",
    "mujeres = stroke_df.loc[stroke_df[\"gender\"] == \"Female\"]\n",
    "mujeres_edades = mujeres[\"age\"]\n",
    "\n",
    "# Crea la figura y los subplots\n",
    "fig, (ax2, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Histograma para mujeres\n",
    "sns.histplot(data=mujeres_edades, bins=10, color=\"violet\", element=\"step\", ax=ax2)\n",
    "ax2.set_xlabel(\"Edad mujeres\")\n",
    "ax2.set_ylabel(\"Cantidad de pacientes afectadas\")\n",
    "\n",
    " # Histograma para hombres\n",
    "sns.histplot(data=hombres_edades, bins=10, color=\"green\", element=\"step\", ax=ax1)\n",
    "ax1.set_xlabel(\"Edad hombres\")\n",
    "ax1.set_ylabel(\"Cantidad de pacientes afectados\")\n",
    "\n",
    "# Ajusta el espacio entre subplots\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "\n",
    "# Agrega leyenda\n",
    "#plt.legend(loc='upper center', ncol=2)\n",
    "\n",
    "# Adición de título general\n",
    "figtext(0.49, 0.95, 'Distribución de las edades de personas que han sufrido un ataque', ha='center', va='top', fontsize=14)\n",
    "\n",
    "# Muestra el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Elección e implementación del algoritmo de regresión**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se extraen del dataset aquellas columnas que contienen strings que no pueden ser interpretado por el modelo\n",
    "dfx = df1.copy()\n",
    "dfx = dfx.drop(columns= ['avg_glucose_level', 'gender', 'ever_married', 'work_type',\t'Residence_type', 'smoking_status'])\n",
    "dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable y\n",
    "dfy = df1[['avg_glucose_level']]\n",
    "dfy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(dfx,dfy,test_size=0.3,random_state=2)\n",
    "# Creación el modelo\n",
    "lr = LinearRegression()\n",
    "# Ajuste del modelo con X_train y y_train\n",
    "lr.fit(X_train,y_train)\n",
    "# Predicción con X_test\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test['avg_glucose_level'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cálculo del error absoluto medio entre el y_test y el valor predicho\n",
    "print(\"MAE\",mean_absolute_error(y_test,y_pred))\n",
    "#aquí se compara el valor obtenido MAE con la media de la línea anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cálculo del error cuadrático medio entre el valor real y y el valor predicho\n",
    "print(\"MSE\",mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cálculo de la raíz cuadrada error cuadrático medio entre el valor real y y el valor predicho\n",
    "print(\"RMSE\",np.sqrt(mean_squared_error(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE logarítmcia\n",
    "print(\"RMSE\",np.log(np.sqrt(mean_squared_error(y_test,y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 entre y_test y el y predicho\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor R2 obtenido da muy cercano a 0 lo cual indica que el modelo propuesto no es eficaz al momento de realizar la predección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A continuación se aplica el método PCA para evaluar resultados y verificar su eficacia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los datos para poder trabajar mejor con mis variables\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplico método de PCA\n",
    "\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train) #entrena y transforma X_train\n",
    "X_test = pca.transform(X_test) # transforma X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de la varianza\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para tener un acierto de variavilidad de aproximadamente 90% me quedo con 5\n",
    "# componentes principales\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del modelo\n",
    "lr = LinearRegression()\n",
    "# Ajustar el modelo con X_train y y_train\n",
    "lr.fit(X_train,y_train)\n",
    "# Predección con X_test\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de métricas\n",
    "\n",
    "# Cálculo del Mean Absolute Error (MAE) entre el valor real y y el valor predicho\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "mae = round(mae, 3)\n",
    "print(\"_ El Mean Absolute Error (MAE) del modelo es\",mae)\n",
    "\n",
    "# Cálculo del Median Absolute Error (Med AE) entre el valor real y y el valor predicho\n",
    "med_ae = median_absolute_error(y_test,y_pred)\n",
    "med_ae = round(med_ae, 3)\n",
    "print(\"_ El Median Absolute Error (Med AE) del modelo es\", med_ae)\n",
    "\n",
    "# Cálculo del Relative Absolute Error (RAE)\n",
    "mean_y_test = np.mean(y_test)\n",
    "rae = mean_absolute_error(y_test,y_pred)/mean_y_test\n",
    "rae = round(rae, 3)\n",
    "print(\"_ El Relative Absolute Error (RAE) del modelo es\", rae)\n",
    "\n",
    "# Cálculo de la raíz cuadrada error cuadrático medio (RMSE) entre el valor real y y el valor predicho\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "rmse = round(rmse, 3)\n",
    "print(\"_ El Root Mean Square Error (RMSE) del modelo es\",rmse)\n",
    "\n",
    "# R2 entre y_test y el y predicho\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "r2 = round(r2, 3)\n",
    "print(\"_ El coeficiente de determinación (R2) del modelo es \",r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creación e incorporación de variable sintética al modelo elegido**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se extraen del dataset aquellas columnas que contienen strings que no pueden ser interpretado por el modelo reincor\n",
    "dfz = df1.copy()\n",
    "dfz = dfz.drop(columns= ['gender', 'ever_married', 'work_type',\t'Residence_type', 'smoking_status'])\n",
    "dfz\n",
    "\n",
    "# Creación de variable sintética\n",
    "\n",
    "# Se opta por multiplicar la edad con el nivel promedio de glucosa (de cada\n",
    "# paciente) para establecer un valor que permita ver si existe una correlación\n",
    "# entre ambas variables, ya que se espera que a mayor edad, mayor sea el nivel\n",
    "# de glusoca del paciente en cuestión. La atención debe centrarse solo en el\n",
    "# valor de la variable (escalar), ya que de la multiplicación surge una mezcla de unidades\n",
    "# que no representan ninguna variable en particular o existente.\n",
    "\n",
    "dfz['var_sint'] = dfz[\"age\"]*dfz[\"avg_glucose_level\"]\n",
    "dfz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se procede nuevameente con la separación de train y test\n",
    "X_train,X_test,y_train,y_test = train_test_split(dfz,dfy,test_size=0.3,random_state=42)\n",
    "\n",
    "# Normalización de los datos para poder trabajar mejor con mis variables\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalización de los datos para poder trabajar mejor con mis variables\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Aplico método de PCA\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train) #entrena y transforma X_train\n",
    "X_test = pca.transform(X_test) # transforma X_test\n",
    "\n",
    "# Nuevo análisis de la varianza\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para tener un acierto de variavilidad de aproximadamente 90% me quedo con 6\n",
    "# componentes principales\n",
    "\n",
    "pca = PCA(n_components=6)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# Creación del modelo\n",
    "lr = LinearRegression()\n",
    "# Ajustar el modelo con X_train y y_train\n",
    "lr.fit(X_train,y_train)\n",
    "# Predección con X_test\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cálculo de métricas\n",
    "\n",
    "# Cálculo del Mean Absolute Error (MAE) entre el valor real y y el valor predicho\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "mae = round(mae, 3)\n",
    "print(\"_ El Mean Absolute Error (MAE) del modelo es\",mae)\n",
    "\n",
    "# Cálculo del Median Absolute Error (Med AE) entre el valor real y y el valor predicho\n",
    "med_ae = median_absolute_error(y_test,y_pred)\n",
    "med_ae = round(med_ae, 3)\n",
    "print(\"_ El Median Absolute Error (Med AE) del modelo es\", med_ae)\n",
    "\n",
    "# Cálculo del Relative Absolute Error (RAE)\n",
    "mean_y_test = np.mean(y_test)\n",
    "rae = mean_absolute_error(y_test,y_pred)/mean_y_test\n",
    "rae = round(rae, 3)\n",
    "print(\"_ El Relative Absolute Error (RAE) del modelo es\", rae)\n",
    "\n",
    "# Cálculo de la raíz cuadrada error cuadrático medio (RMSE) entre el valor real y y el valor predicho\n",
    "rmse = np.sqrt(mean_squared_error(y_test,y_pred))\n",
    "rmse = round(rmse, 3)\n",
    "print(\"_ El Root Mean Square Error (RMSE) del modelo es\",rmse)\n",
    "\n",
    "# R2 entre y_test y el y predicho\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "r2 = round(r2, 3)\n",
    "print(\"_ El coeficiente de determinación (R2) del modelo es \",r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOOCV - regresión\n",
    "Se opta utulizar el agregado de la variable sintética \"var_sint\" ya que en el\n",
    "trabajo previo su incorporación mejoró notablemente las métricas demostrando\n",
    "ser un mejor dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación en X e y\n",
    "data= dfz.values\n",
    "X, y = data[:, :-2], data[:, -2]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# Creación del procedimiento LOOCV\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "# creación el modelo\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=10,max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- TIEMPO APROXIMADO DE EJECUCIÓN: 19 MINUTOS --- ###\n",
    "\n",
    "# Se crean las funciones para poder obtener las métricas MSE y R2 que finalmente\n",
    "# permitirán una justa comparación con el siguiente modelo (Validación simple)\n",
    "def rmse_scorer(estimador, X, y):\n",
    "    y_pred = estimador.predict(X)\n",
    "    return mean_squared_error(y, y_pred)\n",
    "\n",
    "def r2_scorer(estimador, X, y):\n",
    "    y_pred = estimador.predict(X)\n",
    "    return r2_score(y, y_pred)\n",
    "\n",
    "\n",
    "# Evaluación del modelo (criterio de comparacion con R2)\n",
    "# Decidí ajustar cv=5 ya que con el propuesto en clase cv = LeaveOneOut()\n",
    "# R2_scores arrojaba un error computacional\n",
    "R2_scores = cross_val_score(model, X, y, scoring=r2_scorer, cv=5, verbose=1)\n",
    "# Converción a positivos\n",
    "R2_scores = abs(R2_scores)\n",
    "\n",
    "\n",
    "# Evaluación del modelo (criterio de comparacion con MSE)\n",
    "MSE_scores = cross_val_score(model, X, y, scoring=rmse_scorer, cv=cv, verbose=1)\n",
    "# Converción a positivos\n",
    "MSE_scores = abs(MSE_scores)\n",
    "\n",
    "\n",
    "# Evaluación del modelo (criterio de comparacion MAE)\n",
    "MAE = make_scorer(mean_absolute_error)\n",
    "scores = cross_val_score(model, X, y, scoring=MAE, cv=cv,verbose=1) # se guardan las métricas\n",
    "# Converción a positivos\n",
    "scores = abs(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporte de la performance\n",
    "print('MAE: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n",
    "print('MSE: %.3f (%.3f)' % (np.mean(MSE_scores), np.std(MSE_scores)))\n",
    "print('R2: %.3f (%.3f)' % (np.mean(R2_scores), np.std(R2_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de train y test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2, shuffle=True)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo\n",
    "model =RandomForestRegressor(random_state=42, n_estimators=10,max_depth=4)\n",
    "# Ajuste\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones= model.predict(X_test)\n",
    "# Validacion simple\n",
    "print('MSE: ',mean_squared_error(y_true= y_test, y_pred= predicciones))\n",
    "print('MAE: ',mean_absolute_error(y_true= y_test, y_pred= predicciones))\n",
    "print('R2: ',r2_score(y_true= y_test, y_pred= predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con base en los resultados actuales de las métricas, es difícil determinar de manera definitiva cuál método de validación produce un mejor modelo.\n",
    "\n",
    "Las diferencias en las métricas son pequeñas y podrían estar influenciadas por diversos factores como el tamaño del conjunto de datos, la complejidad del modelo y la sensibilidad al sobreajuste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
